# Doesn't work right now, will troubleshoot some other time
RQ_by_Bin <- ggplot(data = Sophie_Graph_Data,
mapping = aes(x = Year,
y = Probability,
fill = RQ_Bin)) +
geom_col(position = position_fill(reverse = TRUE)) +
facet_grid(rows = vars(Population_Scenario),
cols = vars(WWTP_Removal_Scenario)) +
scale_fill_viridis_d(option = "inferno", direction = 1)
RQ_by_Bin
ggplot(data = Sales_Projections_Records %>% filter(sYear != 2019),
mapping = aes(x = sYear,
y = Total_Sold_g,
colour = Scenario)) +
geom_path() +
facet_wrap(facets = vars(API_Name))
View(Sales_Projections_Records)
View(Sales_Projections_21C)
ggplot(data = Sales_Projections_21C %>% filter(sYear != 2019),
mapping = aes(x = Population,
y = Total_Sold_g,
colour = Scenario)) +
geom_path() +
facet_wrap(facets = vars(API_Name))
ggplot(data = Sales_Projections_21C %>% filter(Year != 2019),
mapping = aes(x = Population,
y = Total_Sold_g,
colour = Scenario)) +
geom_path() +
facet_wrap(facets = vars(API_Name))
ggplot(data = Sales_Projections_21C %>% filter(Year != 2019),
mapping = aes(x = Population,
y = Sales_Proj_g,
colour = Scenario)) +
geom_path() +
facet_wrap(facets = vars(API_Name))
ggplot(data = Sales_Projections_21C %>% filter(Year != 2019),
mapping = aes(x = Population,
y = Sales_Proj_g,
colour = Scenario)) +
geom_path() +
facet_wrap(facets = vars(API_Name),
scales = "free")
library(tidyverse)
library(lme4)
library(readxl)
library(drc)
library(TTR)
library(forecast)
library(sjPlot)
# Task: Load in NIPH data back to 199-whenever
getwd()
NIPH_Sales_Weights <- read_excel(path = "Data/NIPH_DB/t830_Product_API_sold_per_year_20220629.xlsx")
# Immediately shortlist to interesting APIs to save time later
Interesting_APIs <- c("estradiol", "ethinylestradiol", "levonorgestrel", "diclofenac",
"ibuprofen", "paracetamol", "ciprofloxacin", "amoxicillin")
NIPH_Sales_Weights <- NIPH_Sales_Weights %>% filter(API_Name %in% Interesting_APIs)
# To calculate historic PECs, we'll need historic population and WW production figures
# mainland Norwegian population on 1 Jan per year 1951 - 2021
# accessed from https://data.ssb.no/api/v0/en/table/06913/
# 15:57 12/05/2021
Norway_Population_Year <- read_xlsx(path = "Data/Statistics_Norway/Pop_1951_2021.xlsx",
range = "B4:C74",
col_names = c("Year", "Population")) %>%
mutate(Year = as.numeric(Year))
# wastewater consumption per person per day in Norway 2015 - 2020 (SSB)
# accessed from https://data.ssb.no/api/v0/en/table/11787/
# 14:49 12/05/2021
Norway_Wastewater_Year <- read_xlsx(path = "Data/Statistics_Norway/WW_per_PD_2015_2020.xlsx",
range = "B4:G5") %>%
# Pivot into long data
pivot_longer(cols = 1:6,
names_to = "Year",
values_to = "L_per_person_per_day") %>%
# Make sure Year is numeric so it doesn't break everything
mutate(Year = as.numeric(Year)) %>%
# Obviously this doesn't go back far enough, so we'll backfill it to 1999 with fake data
add_row(Year = 1999:2014, L_per_person_per_day = 180)
# Norwegian Population Predictions from SSB (No Uncertainty Included)
Norway_Population_Projections_21C <- read_xlsx(path = "Data/Statistics_Norway/Pop_Forecasts_21C.xlsx",
range = "B4:J7") %>%
rename("Scenario" = `...1`) %>%
pivot_longer(cols = 2:9,
names_to = "Year",
values_to = "Population") %>%
mutate(Year = as.double(Year))
# PNECs for our interesting APIs
API_PNECs <- read.csv(file = "Data/APIs_PBMT_byYear_2022-09-01_12.12.csv") %>%
dplyr::select(API_Name, PNEC_gL) %>%
filter(API_Name %in% Interesting_APIs) %>%
distinct()
NIPH_Sales_Weights_Summed <- NIPH_Sales_Weights %>%
group_by(API_Name, sYear) %>%
summarise(Total_Sold_g = sum(API_AmountSoldValue, na.rm = TRUE))
ggplot(data = NIPH_Sales_Weights_Summed,
mapping = aes(x = sYear, y = Total_Sold_g, colour = API_Name)) +
geom_line() +
scale_y_continuous(trans = "log10")
API_sales_by_population <-
NIPH_Sales_Weights_Summed %>% left_join(y = Norway_Population_Year, by = c("sYear" = "Year"))
ggplot(data = API_sales_by_population, mapping =
aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
geom_smooth(method = "lm") +
scale_y_log10()
# Calculate a linear relationship between sales and population
# Sales_over_Pop <- lm(Total_Sold_g ~  API_Name:Population, data = API_sales_by_population) %>%
# coef() %>%
#   as.list() %>%
#   as.tibble() %>%
#   pivot_longer(cols = 2:9) %>%
#   transmute(API_Name = str_remove_all(string = name, pattern = "(API_Name)|(:Population)"),
#             Sales_over_Pop_g = value)
# Pretty sure the above lm sucked, so let's try running individual LMs
# TODO: Previously I ran all this stuff with 2019 left in. Let's take it out.
LMs_API <- API_sales_by_population %>%
filter(sYear != 2019) %>%
group_by(API_Name) %>%
# NB: The formula x ~ y -1 should calculate an lm without an intercept
# This was (may have been) causing me big problems before
summarise(lm_coef = coef(lm(Total_Sold_g ~ Population - 1))[[1]])
ggplot(data = Norway_Population_Projections_21C, mapping = aes(
x = Year,
y = Population,
colour = Scenario,
group = Scenario)) +
geom_point() +
geom_path()
# Run some examples and see how it looks graphed
Sales_Projections_21C <-
crossing(LMs_API, Norway_Population_Projections_21C) %>%
mutate(Sales_Proj_g = Population * lm_coef)
# Join projections and records together to plot on one graph
Sales_Projections_Records <- Sales_Projections_21C %>%
transmute(API_Name,
Total_Sold_g = Sales_Proj_g,
sYear = Year,
Scenario) %>%
add_row(NIPH_Sales_Weights_Summed %>% transmute(API_Name,
sYear,
Total_Sold_g,
Scenario = "Measured"))
ggplot(data = Sales_Projections_Records %>% filter(API_Name %in% c("paracetamol","ethinylestradiol")),
mapping = aes(x = sYear,
y = Total_Sold_g,
colour = API_Name,
shape = Scenario)) +
geom_point() +
scale_y_log10()
ggplot(data = API_sales_by_population, mapping =
aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
geom_smooth(method = "lm") +
scale_y_log10()
ggplot(data = Norway_Population_Projections_21C, mapping = aes(
x = Year,
y = Population,
colour = Scenario,
group = Scenario)) +
geom_point() +
geom_path()
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point()
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
ylim(c(0. 3e8))
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
ylim(c(0, 3e8))
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
ylim(c(0, 3e8)) +
scale_y_log10()
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0, 3e8))
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8))
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth()
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm")
?geom_smooth
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm", se= FALSE, fullrange = TRUE)
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm", se= FALSE, fullrange = TRUE, formula = x ~ y - 1)
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm", se= FALSE, fullrange = TRUE, formula = Total_Sold_g ~ Population - 1)
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm", se= FALSE, fullrange = TRUE, formula = x ~ y - 1)
ggplot(data = API_sales_by_population,
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm", se= FALSE, fullrange = TRUE, formula = y ~ 0 + x)
ggplot(data = API_sales_by_population %>% filter(sYear != 2019),
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm", se= FALSE, fullrange = TRUE, formula = y ~ x)
ggplot(data = API_sales_by_population %>% filter(sYear != 2019),
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "lm", se= FALSE, fullrange = TRUE, formula = y ~ 0 + x)
?geom_smooth
ggplot(data = API_sales_by_population %>% filter(sYear != 2019),
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "glm", se= FALSE, fullrange = TRUE, formula = y ~ 0 + x)
ggplot(data = API_sales_by_population %>% filter(sYear != 2019),
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(method = "glm", se= FALSE, fullrange = TRUE, formula = y ~ 0 + x)
ggplot(data = API_sales_by_population %>% filter(sYear != 2019),
mapping = aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
xlim(c(0, 1e7)) +
scale_y_log10(limits = c(0.1, 3e8)) +
geom_smooth(se = FALSE, fullrange = TRUE)
library(tidyverse)
library(lme4)
library(readxl)
library(drc)
library(TTR)
library(forecast)
library(sjPlot)
# Task: Load in NIPH data back to 199-whenever
getwd()
NIPH_Sales_Weights <- read_excel(path = "Data/NIPH_DB/t830_Product_API_sold_per_year_20220629.xlsx")
# Immediately shortlist to interesting APIs to save time later
Interesting_APIs <- c("estradiol", "ethinylestradiol", "levonorgestrel", "diclofenac",
"ibuprofen", "paracetamol", "ciprofloxacin", "amoxicillin")
NIPH_Sales_Weights <- NIPH_Sales_Weights %>% filter(API_Name %in% Interesting_APIs)
# To calculate historic PECs, we'll need historic population and WW production figures
# mainland Norwegian population on 1 Jan per year 1951 - 2021
# accessed from https://data.ssb.no/api/v0/en/table/06913/
# 15:57 12/05/2021
Norway_Population_Year <- read_xlsx(path = "Data/Statistics_Norway/Pop_1951_2021.xlsx",
range = "B4:C74",
col_names = c("Year", "Population")) %>%
mutate(Year = as.numeric(Year))
# wastewater consumption per person per day in Norway 2015 - 2020 (SSB)
# accessed from https://data.ssb.no/api/v0/en/table/11787/
# 14:49 12/05/2021
Norway_Wastewater_Year <- read_xlsx(path = "Data/Statistics_Norway/WW_per_PD_2015_2020.xlsx",
range = "B4:G5") %>%
# Pivot into long data
pivot_longer(cols = 1:6,
names_to = "Year",
values_to = "L_per_person_per_day") %>%
# Make sure Year is numeric so it doesn't break everything
mutate(Year = as.numeric(Year)) %>%
# Obviously this doesn't go back far enough, so we'll backfill it to 1999 with fake data
add_row(Year = 1999:2014, L_per_person_per_day = 180)
# Norwegian Population Predictions from SSB (No Uncertainty Included)
Norway_Population_Projections_21C <- read_xlsx(path = "Data/Statistics_Norway/Pop_Forecasts_21C.xlsx",
range = "B4:J7") %>%
rename("Scenario" = `...1`) %>%
pivot_longer(cols = 2:9,
names_to = "Year",
values_to = "Population") %>%
mutate(Year = as.double(Year))
# PNECs for our interesting APIs
API_PNECs <- read.csv(file = "Data/APIs_PBMT_byYear_2022-09-01_12.12.csv") %>%
dplyr::select(API_Name, PNEC_gL) %>%
filter(API_Name %in% Interesting_APIs) %>%
distinct()
NIPH_Sales_Weights_Summed <- NIPH_Sales_Weights %>%
group_by(API_Name, sYear) %>%
summarise(Total_Sold_g = sum(API_AmountSoldValue, na.rm = TRUE))
ggplot(data = NIPH_Sales_Weights_Summed,
mapping = aes(x = sYear, y = Total_Sold_g, colour = API_Name)) +
geom_line() +
scale_y_continuous(trans = "log10")
LMs_API <- API_sales_by_population %>%
mutate(KPopulation = Population / 1000) %>%
filter(sYear != 2019) %>%
group_by(API_Name) %>%
# NB: The formula x ~ y -1 should calculate an lm without an intercept
# This was (may have been) causing me big problems before
summarise(lm_coef = coef(lm(Total_Sold_g ~ KPopulation + Year))[[1]])
API_sales_by_population <-
NIPH_Sales_Weights_Summed %>% left_join(y = Norway_Population_Year, by = c("sYear" = "Year"))
ggplot(data = API_sales_by_population, mapping =
aes(x = Population,
y = Total_Sold_g,
colour = API_Name)) +
geom_point() +
geom_smooth(method = "lm") +
scale_y_log10()
LMs_API <- API_sales_by_population %>%
mutate(KPopulation = Population / 1000) %>%
filter(sYear != 2019) %>%
group_by(API_Name) %>%
# NB: The formula x ~ y -1 should calculate an lm without an intercept
# This was (may have been) causing me big problems before
summarise(lm_coef = coef(lm(Total_Sold_g ~ KPopulation + Year))[[1]])
LMs_API <- API_sales_by_population %>%
mutate(KPopulation = Population / 1000) %>%
filter(sYear != 2019) %>%
group_by(API_Name)
View(Hugin_Data_File)
View(LMs_API)
LMs_API <- API_sales_by_population %>%
mutate(KPopulation = Population / 1000) %>%
filter(sYear != 2019) %>%
group_by(API_Name) %>%
# NB: The formula x ~ y -1 should calculate an lm without an intercept
# This was (may have been) causing me big problems before
summarise(lm_coef = coef(lm(Total_Sold_g ~ KPopulation + sYear))[[1]])
LMs_API <- API_sales_by_population %>%
mutate(KPopulation = Population / 1000) %>%
filter(sYear != 2019) %>%
group_by(API_Name)
lm(data = LMs_API, Total_Sold_g ~ KPopulation + sYear)
test_lm <- lm(data = LMs_API, Total_Sold_g ~ KPopulation + sYear)
View(test_lm)
summary(test_lm)
plot(test_lm)
test_lm[1]
test_lm[2]
test_lm[1]
test_lm[1,1]
test_lm[1,0]
coef(test_lm)
coef(test_lm)[1]
LMs_API <- API_sales_by_population %>%
mutate(KPopulation = Population / 1000) %>%
filter(sYear != 2019) %>%
group_by(API_Name) %>%
summarise(lm_intercept = coef(lm(Total_Sold_g ~ KPopulation + sYear))[[1]],
lm_coef_kpop = coef(lm(Total_Sold_g ~ KPopulation + sYear))[[2]],
lm_coef_year = coef(lm(Total_Sold_g ~ KPopulation + sYear))[[3]])
# Make data files for automated data input/output to Hugin
Hugin_Data_File <- LMs_API %>%
left_join(API_PNECs, by = "API_Name") %>%
transmute(API_Name,
API_LM_Intercept = lm_intercept,
API_LM_Coeff_KPop = lm_coef_kpop,
API_LM_Coeff_Year = lm_coef_year,
API_PNEC_gL = PNEC_gL) %>%
# Use vector recycling via crossing to set up the various scenario combinations easily
crossing(Population_Scenario = as_factor(c("Low", "Main", "High")),
Year = c("2020", "2030", "2040", "2050", "2060", "2070", "2080", "2090", "2100"),
WWTP_Removal_Scenario = c("0", "0.25", "0.5", "0.75")) %>%
add_column(`[MEAN](Norway_Population_mil)` = NA,
`[MEAN](API_Sales_Weight_kg)` = NA,
`[MEAN](Water_Consumption_ML)` = NA,
`[MEAN](PEC_Inf_gL)` = NA,
`[MEAN](PEC_Eff_gL)` = NA,
`[MEAN](PEC_SW_gL)` = NA,
`[MEAN](RQ)` = NA,
`P(RQ=0-1)` = NA,
`P(RQ=1-10)` = NA,
`P(RQ=10-100)` = NA,
`P(RQ=100-1000)` = NA,
`P(RQ=1000-10000)` = NA,
`P(RQ=10000-inf)` = NA)
write_csv(x = Hugin_Data_File, file = "Data/Hugin/R_to_Hugin_datafile.csv", na = "")
# Make data files for automated data input/output to Hugin
Hugin_Data_File <- LMs_API %>%
left_join(API_PNECs, by = "API_Name") %>%
transmute(API_Name,
API_LM_Intercept = lm_intercept,
API_LM_Coeff_KPop = lm_coef_kpop,
API_LM_Coeff_Year = lm_coef_year,
API_PNEC_gL = PNEC_gL) %>%
# Use vector recycling via crossing to set up the various scenario combinations easily
crossing(Population_Scenario = as_factor(c("Low", "Main", "High")),
Year = c("2020", "2030", "2040", "2050", "2060", "2070", "2080", "2090", "2100"),
WWTP_Removal_Scenario = c("0", "0.25", "0.5", "0.75")) %>%
add_column(`[MEAN](Norway_Population_mil)` = NA,
`[MEAN](API_Sales_Weight_kg)` = NA,
`[MEAN](Water_Consumption_ML)` = NA,
`[MEAN](PEC_Inf_gL)` = NA,
`[MEAN](PEC_Eff_gL)` = NA,
`[MEAN](PEC_SW_gL)` = NA,
`[MEAN](RQ)` = NA,
`P(RQ=0-1)` = NA,
`P(RQ=1-10)` = NA,
`P(RQ=10-100)` = NA,
`P(RQ=100-1000)` = NA,
`P(RQ=1000-10000)` = NA,
`P(RQ=10000-inf)` = NA)
write_csv(x = Hugin_Data_File, file = "Data/Hugin/R_to_Hugin_datafile.csv", na = "")
# Hugin has done its thing, so let's import the data
Hugin_Data_Output <- read_csv(file = "Data/Hugin/Hugin_to_R_datafile.csv",
show_col_types = FALSE) %>%
# rename_with(cols = 8:15, ~str_remove(string = ., pattern = "\\[MEAN\\]")) %>%
# rename_with(cols = 8:15, ~str_remove_all(string = ., pattern = "\\W"))
# Need to refactorise population scenarios
mutate(Population_Scenario = fct_relevel(Population_Scenario, c("Low", "Main", "High")))
SW_by_Year_Scen_API <- ggplot(data = Hugin_Data_Output,
mapping = aes(x = Year,
y = `[MEAN](API_Sales_Weight_kg)`,
colour = Population_Scenario,
shape = Population_Scenario)) +
geom_point() +
geom_path() +
facet_wrap(facets = vars(API_Name), ncol = 4, scales = "free") +
scale_color_discrete(breaks = c("Low", "Main", "High")) +
scale_shape_discrete(breaks = c("Low", "Main", "High"))
SW_by_Year_Scen_API
# Hugin has done its thing, so let's import the data
Hugin_Data_Output <- read_csv(file = "Data/Hugin/Hugin_to_R_datafile.csv",
show_col_types = FALSE) %>%
# rename_with(cols = 8:15, ~str_remove(string = ., pattern = "\\[MEAN\\]")) %>%
# rename_with(cols = 8:15, ~str_remove_all(string = ., pattern = "\\W"))
# Need to refactorise population scenarios
mutate(Population_Scenario = fct_relevel(Population_Scenario, c("Low", "Main", "High")))
SW_by_Year_Scen_API <- ggplot(data = Hugin_Data_Output,
mapping = aes(x = Year,
y = `[MEAN](API_Sales_Weight_kg)`,
colour = Population_Scenario,
shape = Population_Scenario)) +
geom_point() +
geom_path() +
facet_wrap(facets = vars(API_Name), ncol = 4, scales = "free") +
scale_color_discrete(breaks = c("Low", "Main", "High")) +
scale_shape_discrete(breaks = c("Low", "Main", "High"))
SW_by_Year_Scen_API
(7 * -1049.53765 * 1000)
(7 * -1049.53765 * 1000) + (180030.5 * 2020) + (-354463413)
(7 * -1049.53765 * 1000) + (180030.5 * 2100) + (-354463413)
(5 * -1049.53765 * 1000) + (180030.5 * 2100) + (-354463413)
(5 * -1049.53765 * 1000) + (180030.5 * 2020) + (-354463413)
(10 * -1049.53765 * 1000) + (180030.5 * 2200) + (-354463413)
