mutate(County_Code = str_extract(string = County, pattern = "[0-9]{2}"),
County_Name = str_extract(string = County, pattern = "[A-z](?:(?! -).)*")) %>%
select(-County)
county_codes <- large_wwtp_by_county_2020 %>%
select(County_Code, County_Name)
### SSB: mainland Norwegian population on 1 Jan per year 1951 - 2021 (06913)
Norway_Population_Year <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_1951_2021.xlsx",
range = "B4:C74",
col_names = c("Year", "Population")) %>%
mutate(Year = as.numeric(Year))
### SSB: wastewater consumption per person per day in Norway 2015 - 2020 (11787)
Norway_Wastewater_Year <- read_xlsx(path = "data/raw/Statistics_Norway/WW_per_PD_2015_2020.xlsx",
range = "B4:G5") %>%
# Pivot into long data
pivot_longer(cols = 1:6,
names_to = "Year",
values_to = "L_per_person_per_day") %>%
# Make sure Year is numeric so it doesn't break everything
mutate(Year = as.numeric(Year)) %>%
# Obviously this doesn't go back far enough, so we'll backfill it to 1999 with fake data
add_row(Year = 1999:2014, L_per_person_per_day = 180)
### SSB: Norwegian Population Predictions (No Uncertainty Included)
Norway_Population_Projections_21C <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_Forecasts_21C.xlsx",
range = "B4:J7") %>%
rename("Scenario" = `...1`) %>%
pivot_longer(cols = 2:9,
names_to = "Year",
values_to = "Population") %>%
mutate(Year = as.double(Year))
write_csv(x = pop_by_county_2020, file = "API_RQ_BN/data/temp/pop_by_county_2020.csv")
write_csv(x = pop_by_county_2020, file = "data/temp/pop_by_county_2020.csv")
### SSB WWTP TREATMENT AND CONNECTION BY MUNICIPALITY, 2020
# https://www.ssb.no/en/statbank/table/11793/tableViewLayout1/
WWTP_connection_by_municipality <- read_excel(path = "data/raw/Statistics_Norway/Norway_WWTP_Connect_Regions_2020.xlsx",
skip = 2,
col_names = c("Municipality",
"Pop_Connected_WWTP_>50PE",
"Pop_Connected_WWTP_>50PE_Chem_Treat",
"Pop_Connected_WWTP_>50PE_BioChem_Treat",
"Pop_Connected_WWTP_>50PE_BioChemMechNat_Treat",
"Pop_Connected_WWTP_>50PE_No_Treat")) %>%
na_if(y = "..") %>%
# Remove old kommune and KOSTRA counties
filter(!is.na(Municipality),
`Pop_Connected_WWTP_>50PE` != ".",
!str_detect(string = Municipality, pattern = "EAK"),
!str_detect(string = Municipality, pattern = "EKA"))
write_csv(x = WWTP_connection_by_municipality, file = "data/temp/WWTP_connection_by_municipality.csv")
# Import Statistics Norway data from raw files, and create temp files in a tidy format
### SSB POPULATION BY COUNTY/FYLKE, 2020 BORDERS (11342)
pop_by_county_2020 <- read_excel(path = "data/raw/Statistics_Norway/Pop_2020_Counties.xlsx",
range = "A5:B15",
col_names = c("County", "Population")) %>%
transmute(County_Code = str_extract(string = County, pattern = "[0-9]{2}"),
Population)
# Save to temp
write_csv(x = pop_by_county_2020, file = "data/temp/pop_by_county_2020.csv")
### SSB WWTP TREATMENT AND CONNECTION BY MUNICIPALITY, 2020
# https://www.ssb.no/en/statbank/table/11793/tableViewLayout1/
WWTP_connection_by_municipality <- read_excel(path = "data/raw/Statistics_Norway/Norway_WWTP_Connect_Regions_2020.xlsx",
skip = 2,
col_names = c("Municipality",
"Pop_Connected_WWTP_>50PE",
"Pop_Connected_WWTP_>50PE_Chem_Treat",
"Pop_Connected_WWTP_>50PE_BioChem_Treat",
"Pop_Connected_WWTP_>50PE_BioChemMechNat_Treat",
"Pop_Connected_WWTP_>50PE_No_Treat")) %>%
na_if(y = "..") %>%
# Remove old kommune and KOSTRA counties
filter(!is.na(Municipality),
`Pop_Connected_WWTP_>50PE` != ".",
!str_detect(string = Municipality, pattern = "EAK"),
!str_detect(string = Municipality, pattern = "EKA"))
write_csv(x = WWTP_connection_by_municipality, file = "data/temp/WWTP_connection_by_municipality.csv")
### SSB: Inhabitants Connected to Small WWTPs (05272)
# https://www.ssb.no/statbank/table/05272/
small_wwtp_by_county_2020 <- read_excel(path = "data/raw/Statistics_Norway/WWTP_by_County_2020_Small.xlsx",
range = "A6:P16",
col_names = c("County",
"total",
"untreated",
"sludge_seperator",
"biological",
"chemical",
"chemical-biological",
"sludge_seperator_w_infiltration",
"sludge_seperator_w_sand_filter",
"sealed_blackwater_tank",
"biological_toilet",
"sealed_greywater_tank",
"artificial_wetland",
"sealed_blackwater_greywater_filter",
"biological_toilet_greywater_filter",
"other"),
na = "..") %>%
mutate(County_Code = str_extract(string = County, pattern = "[0-9]{2}"),
# Remove the numbers at the start of County, and the Sapmi name if present
County_Name = str_extract(string = County, pattern = "[A-z](?:(?! -).)*")) %>%
select(-County)
write_csv(x = small_wwtp_by_county_2020, file = "data/temp/small_wwtp_by_county_2020.csv")
### SSB: Inhabitants Connected to Large WWTPs (05273)
# https://www.ssb.no/statbank/table/05273/
large_wwtp_by_county_2020 <- read_excel(path = "data/raw/Statistics_Norway/WWTP_by_County_2020_Large.xlsx",
range = "A6:H16",
col_names = c("County",
"total",
"untreated",
"mechanical",
"chemical",
"biological",
"chemical-biological",
"other"),
na = "..") %>%
mutate(County_Code = str_extract(string = County, pattern = "[0-9]{2}"),
County_Name = str_extract(string = County, pattern = "[A-z](?:(?! -).)*")) %>%
select(-County)
write_csv(x = large_wwtp_by_county_2020, file = "data/temp/large_wwtp_by_county_2020.csv")
# Create a helper csv matching county codes to names
county_codes <- large_wwtp_by_county_2020 %>%
select(County_Code, County_Name)
write_csv(x = county_codes, file = "data/temp/county_codes.csv")
### SSB: mainland Norwegian population on 1 Jan per year 1951 - 2021 (06913)
Norway_Population_Year <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_1951_2021.xlsx",
range = "B4:C74",
col_names = c("Year", "Population")) %>%
mutate(Year = as.numeric(Year))
write_csv(x = Norway_Population_Year, file = "data/temp/Norway_Population_Year.csv")
### SSB: wastewater consumption per person per day in Norway 2015 - 2020 (11787)
Norway_Wastewater_Year <- read_xlsx(path = "data/raw/Statistics_Norway/WW_per_PD_2015_2020.xlsx",
range = "B4:G5") %>%
# Pivot into long data
pivot_longer(cols = 1:6,
names_to = "Year",
values_to = "L_per_person_per_day") %>%
# Make sure Year is numeric so it doesn't break everything
mutate(Year = as.numeric(Year)) %>%
# Obviously this doesn't go back far enough, so we'll backfill it to 1999 with fake data
add_row(Year = 1999:2014, L_per_person_per_day = 180)
write_csv(x = Norway_Wastewater_Year, file = "data/temp/Norway_Wastewater_Year.csv")
### SSB: Norwegian Population Predictions (No Uncertainty Included)
Norway_Population_Projections_21C <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_Forecasts_21C.xlsx",
range = "B4:J7") %>%
rename("Scenario" = `...1`) %>%
pivot_longer(cols = 2:9,
names_to = "Year",
values_to = "Population") %>%
mutate(Year = as.double(Year))
write_csv(x = Norway_Population_Projections_21C, file = "data/temp/Norway_Population_Projections_21C.csv")
source(file = "data_importers/statistics_norway_import.R")
source(file = "/data_importers/statistics_norway_import.R")
source(file = "../data_importers/statistics_norway_import.R")
source(file = "src/data_importers/statistics_norway_import.R")
source(file = "src/data_importers/statistics_norway_import.R")
# Import shapefiles from the Norwegian Institute for Public Health's
# Sykdompuls family of packages (splmaps)
# make a small format modification
# Dataframe version
Norway_counties_dataframe <- nor_nuts3_map_b2020_default_dt %>%
mutate(County_Code = str_extract(string = location_code, pattern = "[0-9]{2}"))
# sf version
Norway_counties_sf <- nor_nuts3_map_b2020_default_sf %>%
mutate(County_Code = str_extract(location_code, pattern = "[0-9]{2}"))
# Import shapefiles from the Norwegian Institute for Public Health's
# Sykdompuls family of packages (splmaps)
# make a small format modification
# Dataframe version
Norway_counties_dataframe <- nor_nuts3_map_b2020_default_dt %>%
mutate(County_Code = str_extract(string = location_code, pattern = "[0-9]{2}"))
write_csv(x = Norway_counties_dataframe, file = "data/temp/Norway_counties_dataframe.csv")
# sf version
Norway_counties_sf <- nor_nuts3_map_b2020_default_sf %>%
mutate(County_Code = str_extract(location_code, pattern = "[0-9]{2}"))
write_csv(x = Norway_counties_sf, file = "data/temp/Norway_counties_sf.csv")
source(file = "src/data_importers/statistics_norway_import.R")
source(file = "src/data_importers/spl_map_import.R")
# Import Statistics Norway data from raw files, and create temp files in a tidy format
### SSB POPULATION BY COUNTY/FYLKE, 2020 BORDERS (11342)
pop_by_county_2020 <- read_excel(path = "data/raw/Statistics_Norway/Pop_2020_Counties.xlsx",
range = "A5:B15",
col_names = c("County", "Population")) %>%
transmute(County_Code = str_extract(string = County, pattern = "[0-9]{2}"),
Population)
# Save to temp
write_csv(x = pop_by_county_2020, file = "data/temp/pop_by_county_2020.csv")
### SSB WWTP TREATMENT AND CONNECTION BY MUNICIPALITY, 2020
# https://www.ssb.no/en/statbank/table/11793/tableViewLayout1/
WWTP_connection_by_municipality <- read_excel(path = "data/raw/Statistics_Norway/Norway_WWTP_Connect_Regions_2020.xlsx",
skip = 2,
col_names = c("Municipality",
"Pop_Connected_WWTP_>50PE",
"Pop_Connected_WWTP_>50PE_Chem_Treat",
"Pop_Connected_WWTP_>50PE_BioChem_Treat",
"Pop_Connected_WWTP_>50PE_BioChemMechNat_Treat",
"Pop_Connected_WWTP_>50PE_No_Treat")) %>%
na_if(y = "..") %>%
# Remove old kommune and KOSTRA counties
filter(!is.na(Municipality),
`Pop_Connected_WWTP_>50PE` != ".",
!str_detect(string = Municipality, pattern = "EAK"),
!str_detect(string = Municipality, pattern = "EKA"))
write_csv(x = WWTP_connection_by_municipality, file = "data/temp/WWTP_connection_by_municipality.csv")
### SSB: Inhabitants Connected to Small WWTPs (05272)
# https://www.ssb.no/statbank/table/05272/
small_wwtp_by_county_2020 <- read_excel(path = "data/raw/Statistics_Norway/WWTP_by_County_2020_Small.xlsx",
range = "A6:P16",
col_names = c("County",
"total",
"untreated",
"sludge_seperator",
"biological",
"chemical",
"chemical-biological",
"sludge_seperator_w_infiltration",
"sludge_seperator_w_sand_filter",
"sealed_blackwater_tank",
"biological_toilet",
"sealed_greywater_tank",
"artificial_wetland",
"sealed_blackwater_greywater_filter",
"biological_toilet_greywater_filter",
"other"),
na = "..") %>%
mutate(County_Code = str_extract(string = County, pattern = "[0-9]{2}"),
# Remove the numbers at the start of County, and the Sapmi name if present
County_Name = str_extract(string = County, pattern = "[A-z](?:(?! -).)*")) %>%
select(-County)
write_csv(x = small_wwtp_by_county_2020, file = "data/temp/small_wwtp_by_county_2020.csv")
### SSB: Inhabitants Connected to Large WWTPs (05273)
# https://www.ssb.no/statbank/table/05273/
large_wwtp_by_county_2020 <- read_excel(path = "data/raw/Statistics_Norway/WWTP_by_County_2020_Large.xlsx",
range = "A6:H16",
col_names = c("County",
"total",
"untreated",
"mechanical",
"chemical",
"biological",
"chemical-biological",
"other"),
na = "..") %>%
mutate(County_Code = str_extract(string = County, pattern = "[0-9]{2}"),
County_Name = str_extract(string = County, pattern = "[A-z](?:(?! -).)*")) %>%
select(-County)
write_csv(x = large_wwtp_by_county_2020, file = "data/temp/large_wwtp_by_county_2020.csv")
# Create a helper csv matching county codes to names
county_codes <- large_wwtp_by_county_2020 %>%
select(County_Code, County_Name)
write_csv(x = county_codes, file = "data/temp/county_codes.csv")
### SSB: mainland Norwegian population on 1 Jan per year 1951 - 2021 (06913)
Norway_Population_Year <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_1951_2021.xlsx",
range = "B4:C74",
col_names = c("Year", "Population")) %>%
mutate(Year = as.numeric(Year))
write_csv(x = Norway_Population_Year, file = "data/temp/Norway_Population_Year.csv")
### SSB: wastewater consumption per person per day in Norway 2015 - 2020 (11787)
Norway_Wastewater_Year <- read_xlsx(path = "data/raw/Statistics_Norway/WW_per_PD_2015_2020.xlsx",
range = "B4:G5") %>%
# Pivot into long data
pivot_longer(cols = 1:6,
names_to = "Year",
values_to = "L_per_person_per_day") %>%
# Make sure Year is numeric so it doesn't break everything
mutate(Year = as.numeric(Year)) %>%
# Obviously this doesn't go back far enough, so we'll backfill it to 1999 with fake data
add_row(Year = 1999:2014, L_per_person_per_day = 180)
write_csv(x = Norway_Wastewater_Year, file = "data/temp/Norway_Wastewater_Year.csv")
### SSB: Norwegian Population Predictions (No Uncertainty Included)
Norway_Population_Projections_21C <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_Forecasts_21C.xlsx",
range = "B4:J7") %>%
rename("Scenario" = `...1`) %>%
pivot_longer(cols = 2:9,
names_to = "Year",
values_to = "Population") %>%
mutate(Year = as.double(Year))
write_csv(x = Norway_Population_Projections_21C, file = "data/temp/Norway_Population_Projections_21C.csv")
Norway_Population_Projections_21C <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_Forecasts_21C.xlsx",
range = "B4:J7")
Norway_Population_Projections_21C
?read_xlsx
### SSB: Norwegian Population Predictions (No Uncertainty Included)
Norway_Population_Projections_21C <- read_xlsx(path = "data/raw/Statistics_Norway/Pop_Forecasts_21C.xlsx",
range = "B4:J7",
col_names = c("Scenario", "2030", "2040", "2050", "2060",
"2070", "2080", "2090", "2100")) %>%
pivot_longer(cols = 2:9,
names_to = "Year",
values_to = "Population") %>%
mutate(Year = as.double(Year))
write_csv(x = Norway_Population_Projections_21C, file = "data/temp/Norway_Population_Projections_21C.csv")
source(file = "src/data_importers/statistics_norway_import.R")
source(file = "src/data_importers/spl_map_import.R")
setRepositories()
install.packages("RHugin")
warnings()
install.packages("RHugin")
install.packages("glmm")
# renv::init()
renv::restore()
# Library
library(tidyverse)
library(splmaps)
library(readxl)
library(glue)
# Leaflet stuff
library(splmaps)
library(tidyverse)
library(sf)
library(leaflet)
library(rgdal)
library(shiny)
`%notin%` <- negate(`%in%`)
# Disable summarise informative message:
options(dplyr.summarise.inform = FALSE)
# Set up data from main RMD
pd_county <- splmaps::nor_nuts3_map_b2020_default_sf %>%
mutate(County_Code = str_extract(location_code, pattern = "[0-9]{2}")) %>%
left_join(county_codes, by = "County_Code") %>%
select(-location_code)
avg_RQ_county <- Hugin_Data_Output_Tall %>%
group_by(master_pop_scenario, master_year, master_WWT_scenario, master_county, API_Name) %>%
mutate(Risk_Bin_avg = case_when(Risk_Bin == "0-1" ~ 0.5,
Risk_Bin == "1 - 10" ~ 5.5,
Risk_Bin == "10-100" ~ 55,
Risk_Bin == "100-1000" ~ 550,
Risk_Bin == "1000-10000" ~ 5500,
Risk_Bin == "10000-inf" ~ 10000),
County_Name = master_county) %>%
summarise(Avg_RQ = sum(Risk_Bin_avg * Probability, na.rm = TRUE),
County_Name,
API_Name) %>%
ungroup() %>%
select(-master_county) %>%
distinct()
API_removal_rates <- read_excel(path = "Data/Removal_efficiencies_JvD.xlsx",
range = "A1:M59") %>%
transmute(InChIKey_string = `InChI Key`,
primary_removal = `Primary (conventional settelers)`,
secondary_removal = `Secondary (biological)`,
tertiary_removal = `Tertiary (e.g. metal salts)`,
advanced_removal = `Advanced treatment (Chlorination, UV)`,
ozone_removal = `Ozone`,
activated_carbon_removal = AC) %>%
left_join(API_Sales %>% select(API_Name, InChIKey_string), by = "InChIKey_string") %>%
distinct() %>%
relocate(API_Name) %>%
pivot_longer(cols = 3:8,
names_to = "treatment_removal_rate")
API_removal_rates <- read_excel(path = "Data/Removal_efficiencies_JvD.xlsx",
range = "A1:M59") %>%
transmute(InChIKey_string = `InChI Key`,
primary_removal = `Primary (conventional settelers)`,
secondary_removal = `Secondary (biological)`,
tertiary_removal = `Tertiary (e.g. metal salts)`,
advanced_removal = `Advanced treatment (Chlorination, UV)`,
ozone_removal = `Ozone`,
activated_carbon_removal = AC)
View(API_removal_rates)
# Currently we have two NIPH datasets:
#     1. Sales from 1999-2018, without vet/wholesale metadata
# 2. Sales from 2016-2019, with
#
# TODO: Fix this discrepancy.
### NIPH: Sales weights of APIs, 1999 - 2019 (censored to API level)
NIPH_Sales_Weights_1999_2018 <- read_csv(file = "Data/NIPH_DB/NIPH_sales_weights.csv",
show_col_types = FALSE) %>%
rename(Year = sYear) %>%
# Sales in 2019 are consistently incomplete for all APIs
filter(Year != 2019)
# TODO: Where's the data set for all APIs? This is just "Interesting".
### API Sales Weights
# Own work
API_Sales <- read_csv(file = "Data/sales_by_API_year_processed.csv",
show_col_types = FALSE) %>%
rename(Year = sYear) %>%
filter(ProductSaleGroup == "Total",
Vet != "Total") %>%
select(API_Name, Year, Vet, AmountSold_g, InChIKey_string)
NIPH_Sales_Weights_1999_2018 <- read_csv(file = "data/raw/NIPH_DB/NIPH_sales_weights.csv",
show_col_types = FALSE) %>%
rename(Year = sYear) %>%
# Sales in 2019 are consistently incomplete for all APIs
filter(Year != 2019)
NIPH_Sales_Weights_1999_2018 <- read_csv(file = "data/NIPH_DB/NIPH_sales_weights.csv",
show_col_types = FALSE) %>%
rename(Year = sYear) %>%
# Sales in 2019 are consistently incomplete for all APIs
filter(Year != 2019)
# TODO: Where's the data set for all APIs? This is just "Interesting".
View(NIPH_Sales_Weights_1999_2018)
NIPH_Sales_Weights_1999_2018 <- read_csv(file = "data/NIPH_DB/NIPH_sales_weights.csv",
show_col_types = FALSE) %>%
rename(Year = sYear) %>%
# Sales in 2019 are consistently incomplete for all APIs
filter(Year != 2019)
# TODO: Where's the data set for all APIs? This is just "Interesting".
NIPH_Sales_Weights_Summed <- NIPH_Sales_Weights_1999_2018 %>%
group_by(API_Name, Year) %>%
summarise(Total_Sold_kg = sum(API_AmountSoldValue, na.rm = TRUE) / 1000)
View(NIPH_Sales_Weights_Summed)
write_csv(NIPH_Sales_Weights_Summed, file = "data/raw/API_sales_weights_1999_2018")
write_csv(NIPH_Sales_Weights_Summed, file = "data/raw/API_sales_weights_1999_2018.csv")
# Import Norwegian Institute for Public Health Wholesale Drug Database data
# censored/summarised to the API level, for 8 APIs, 1999 - 2018
API_sales_weights_1999_2018 <- read_csv(file = "data/raw/API_sales_weights_1999_2018.csv")
# Import Norwegian Institute for Public Health Wholesale Drug Database data
# censored/summarised to the API level, for 8 APIs, 1999 - 2018
API_sales_weights_1999_2018 <- read_csv(file = "data/raw/API_sales_weights_1999_2018.csv",
`show_col_types = FALSE`)
# Import Norwegian Institute for Public Health Wholesale Drug Database data
# censored/summarised to the API level, for 8 APIs, 1999 - 2018
API_sales_weights_1999_2018 <- read_csv(file = "data/raw/API_sales_weights_1999_2018.csv",
show_col_types = FALSE)
# Various Statistics Norway datasets
source(file = "src/data_importers/statistics_norway_import.R")
# SPL maps from the Norwegian Institute for Public Health
source(file = "src/data_importers/spl_map_import.R")
# Sales weights for 8 high-risk APIs, adapted from NIPH data
source(file = "src/data_importers/API_sales_import.R")
# renv::init()
renv::restore()
# Library
library(tidyverse)
library(splmaps)
library(readxl)
library(glue)
# Leaflet stuff
library(splmaps)
library(tidyverse)
library(sf)
library(leaflet)
library(rgdal)
library(shiny)
`%notin%` <- negate(`%in%`)
# Disable summarise informative message:
options(dplyr.summarise.inform = FALSE)
source(file = "src/data_importers/statistics_norway_import.R")
# SPL maps from the Norwegian Institute for Public Health
source(file = "src/data_importers/spl_map_import.R")
# Sales weights for 8 high-risk APIs, adapted from NIPH data
source(file = "src/data_importers/API_sales_import.R")
analysed_APIs <- c("estradiol", "ethinylestradiol", "diclofenac",
"ibuprofen", "paracetamol", "ciprofloxacin")
API_sales_weights_1999_2018 <- API_sales_weights_1999_2018 %>%
filter(API_Name %in% analysed_APIs)
View(API_sales_weights_1999_2018)
# Import a table of Norwegian and English language WWT technology definitions
# Own work, adapted from Statistics Norway reports
WWT_definitions_Norway <- read_csv(file = "data/raw/WWT_definitions_norway.csv",
show_col_types = FALSE)
# Import Norwegian Institute for Public Health Wholesale Drug Database data
# censored/summarised to the API level, for 8 APIs, 1999 - 2018
API_sales_weights_1999_2018 <- read_csv(file = "data/raw/API_sales_weights_1999_2018.csv",
show_col_types = FALSE)
# Import a table of Norwegian and English language WWT technology definitions
# Own work, adapted from Statistics Norway reports
WWT_definitions_Norway <- read_excel(file = "data/raw/WWT_definitions_norway.xlsx",
show_col_types = FALSE)
# Import a table of Norwegian and English language WWT technology definitions
# Own work, adapted from Statistics Norway reports
WWT_definitions_Norway <- read_excel(file = "data/raw/WWT_definitions_norway.xlsx")
# Import a table of Norwegian and English language WWT technology definitions
# Own work, adapted from Statistics Norway reports
WWT_definitions_Norway <- read_excel(path = "data/raw/WWT_definitions_norway.xlsx")
# Norwegian and English classifications of WWT technologies
source(file = "src/data_importers/WWT_class_import.R")
# Make data files for automated data input/output to Hugin
Six_Interesting_APIs <- Interesting_APIs
# Make data files for automated data input/output to Hugin
All_RQ_Interval_Nodes <- append(paste0("API_RQ_FW_", str_to_title(analysed_APIs)),
c("SumRQ_Estrogens", "SumRQ_Antibiotics",
"SumRQ_Painkillers","SumRQ_Total"))
All_RQ_Boolean_Nodes <- c("PRQ_1_Estrogens", "PRQ_1_Antibiotics", "PRQ_1_Painkillers", "PRQ_1_Total")
Hugin_Data_File <- tibble(master_pop_scenario = as_factor(c("Low", "Main", "High"))) %>%
# Use vector recycling via crossing to set up the various scenario combinations easily
crossing(master_year = c("2020", "2050"),
master_WWT_scenario = c("Current", "Compliance"),
master_county = unlist(county_codes[2])) %>%
# Add API node value presets
add_column(API_light_ethinylestradiol = "ethinylestradiol",
API_light_estriol = "estriol",
API_medium_diclofenac = "diclofenac",
API_medium_ciprofloxacin = "ciprofloxacin",
API_heavy_paracetamol = "paracetamol",
API_heavy_ibuprofen = "ibuprofen")
# Add columns to monitor RQ intervals for each API and Sum Node
for (v in 1:length(All_RQ_Interval_Nodes)) {
Temp_API_Name <- All_RQ_Interval_Nodes[v]
print(Temp_API_Name)
Hugin_Data_File <- Hugin_Data_File %>%
add_column(!! glue("P(", "{Temp_API_Name}", "=0-1)") := NA,
!! glue("P(", "{Temp_API_Name}", "=1-10)") := NA,
!! glue("P(", "{Temp_API_Name}", "=10-100)") := NA,
!! glue("P(", "{Temp_API_Name}", "=100-1000)") := NA,
!! glue("P(", "{Temp_API_Name}", "=1000-10000)") := NA,
!! glue("P(", "{Temp_API_Name}", "=10000-inf)") := NA)
}
# Likewise for each combined probability node
for (v in 1:length(All_RQ_Boolean_Nodes)) {
Temp_Bool_Name <- All_RQ_Boolean_Nodes[v]
print(Temp_Bool_Name)
Hugin_Data_File <- Hugin_Data_File %>%
add_column(!! glue("P(", "{Temp_Bool_Name}", "=true)") := NA,
!! glue("P(", "{Temp_Bool_Name}", "=false)") := NA)
}
write_csv(x = Hugin_Data_File, file = "Data/Hugin/R_to_Hugin_datafile.csv", na = "")
install.packages("lintr")
install.packages("lintr")
install.packages("lintr")
getOption("download.file.method")
renv:::renv_download_file_method()
renv:::renv_download_file_method()
renv::renv_download_file_method()
