---
title: "Bayesian Network Environmental Risk Assessment of Pharmaceuticals"
output: html_notebook
---

# 1. Setup

```{r packages}
# Library
library(tidyverse)
library(readxl)
library(glue)

# ggplot extensions
library(cowplot)
library(ggpmisc)
library(ggrepel)
library(ragg)
library(EnvStats)

# Mapping/GIS
library(sf)
suppressMessages(library(rnaturalearth)) # supress warnings about sf package depreciation
library(rnaturalearthdata)
library(csmaps)

`%notin%` <- negate(`%in%`)

# Disable summarise informative message:
options(dplyr.summarise.inform = FALSE)

knitr::opts_knit$set(root.dir = here::here())
getwd()
```

# 2. Data
Import Statistics Norway and Norwegian Institute for Public Health (NIPH) data and maps.
```{r data_import}
getwd()
# Various Statistics Norway datasets
source(file = "src/data_importers/import_Norway_data.R")

# Sales weights for 6 high-risk APIs, adapted from NIPH data
source(file = "src/data_importers/import_sales.R")

# API PNECs from various sources
source(file = "src/data_importers/import_PNECs.R")

# van Dijk et al.'s unpublished pharmaceutical removal rates dataset
source(file = "src/data_importers/import_removal.R")
```

# 3. Methods

Population discretisation was manually performed in Hugin, rounding population (in millions) up to the 
next highest 0.5. This is replicated here so we can check our choices of LM parameters.

```{r data_processing_population}
# Discretise population for diagnostic/summary graphs
source(file = "src/data_processing/pop_discretisation_Norway.R")
```

Calculate a linear model of Sales weight (kg), explained by population (mil) and year, plus
an intercept. This is used to predict sales weights under various population scenarios to 2050.

## 3.1 API LMs & Figure 02

```{r data_processing_API}
## Figure 02 ##

# Fit linear models to sales data, and predict future sales from models
source(file = "src/data_processing/API_sales_LM.R")
# Graph out predictions from LMs
source(file = "src/graphics/make_figure02_sales.R")
figure02_sales 

ggsave(filename = "output/images/ready/figure02_sales.tif", device = "tiff",
       width = 23, height = 18, units = "cm", dpi = 300,
       scaling = 1.2)

## Table 03 ##
write_excel_csv(x = LM_parameters, file = "output/tables/tab_03_lm_params.csv")
```

We can automate running through all possible combinations of APIs and scenarios in Hugin using
a data file (essentially a CSV) with scenario variables filled in, and specially formatted empty
columns for variables we want to pull out.

```{r data_processing_Hugin}
source(file = "src/data_processing/R_to_Hugin.R")
```

Now re-import data from Hugin

```{r data_import_Hugin}
source(file = "src/data_importers/import_Hugin_data.R")
# save a copy of data to output
write_excel_csv(x = Hugin_Data_Output_Tall_Labelled,
                file = "output/data/data_output.csv")

```


# 4. Results

## 4.1 Figure 04

```{r make_figure04_population}
## Figure 04 ##
source(file = "src/graphics/make_figure04_population.R")

figure04_population

ggsave(filename = "output/images/ready/figure04_population.tiff", device = "tiff", 
       width = 20, height = 20, units = "cm")

```

## 4.2 Figure 05

```{r make_figure05_WWT}
## Figure 05 ##
source(file = "src/graphics/make_figure05_WWT.R")

figure05_WWT

ggsave(filename = "output/images/ready/figure05_WWT.tif", device = "tiff", 
       width = 20, height = 20, units = "cm")
```

## 4.3 Figure 06

```{r summed_deterministic_risk}
source(file = "src/graphics/make_figure06_summed.R")

figure06_summed

ggsave(filename = "output/images/ready/figure06_summed.tif", device = "tiff", 
       width = 20, height = 20, units = "cm")
```

# S1. Supporting Information

```{r make_supporting_figures}
source(file = "src/graphics/make_figureS01_counties.R")
# figure S02 is hand-made
source(file = "src/graphics/make_figureS03_removal.R")
source(file = "src/graphics/make_figureS04_normals.R")
source(file = "src/graphics/make_figureS05_population.R")
```